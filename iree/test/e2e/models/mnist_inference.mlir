// MNIST model with empty weights, for testing.
//
// Generated by the colab/mnist_training.ipynb notebook with manual edits to
// * remove remaining TensorFlow attributes
// * replace large values with zeros
//
// Note: batch size is set to 32

// RUN: iree-run-mlir -iree-hal-target-backends=vmvx %s -function-input="32x28x28x1xf32" | IreeFileCheck %s
// RUN: [[ $IREE_LLVMAOT_DISABLE == 1 ]] || (iree-run-mlir -iree-hal-target-backends=dylib-llvm-aot %s -function-input="32x28x28x1xf32" | IreeFileCheck %s)
// RUN: [[ $IREE_VULKAN_DISABLE == 1 ]] || (iree-run-mlir -iree-hal-target-backends=vulkan-spirv %s -function-input="32x28x28x1xf32" | IreeFileCheck %s)

#map0 = affine_map<(d0, d1) -> (d0, d1)>
#map1 = affine_map<(d0, d1) -> ()>
#map2 = affine_map<(d0, d1) -> (d0)>
#map3 = affine_map<(d0, d1) -> (d0, 0)>
module  {
  util.global private @"__iree_flow___sm_node22__model.layer-2.kernel" = dense<0.000000e+00> : tensor<784x128xf32>
  util.global private @"__iree_flow___sm_node23__model.layer-2.bias" = dense<0.000000e+00> : tensor<128xf32>
  util.global private @"__iree_flow___sm_node32__model.layer-4.kernel" = dense<0.000000e+00> : tensor<128x10xf32>
  util.global private @"__iree_flow___sm_node33__model.layer-4.bias" = dense<0.000000e+00> : tensor<10xf32>
  // CHECK-LABEL: EXEC @predict
  func @predict(%arg0: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi = "{\22a\22:[[\22ndarray\22,\22f32\22,4,32,28,28,1]],\22r\22:[[\22ndarray\22,\22f32\22,2,32,10]],\22v\22:1}"} {
    %0 = hal.tensor.cast %arg0 : !hal.buffer_view -> tensor<32x28x28x1xf32>
    %1 = call @__inference_predict_40180(%0) : (tensor<32x28x28x1xf32>) -> tensor<32x10xf32>
    %2 = hal.tensor.cast %1 : tensor<32x10xf32> -> !hal.buffer_view
    return %2 : !hal.buffer_view
  }
  func private @__inference_predict_40180(%arg0: tensor<32x28x28x1xf32>) -> tensor<32x10xf32> {
    %cst = constant dense<0.000000e+00> : tensor<f32>
    %cst_0 = constant dense<0.000000e+00> : tensor<784x128xf32>
    %cst_1 = constant dense<0.000000e+00> : tensor<32x128xf32>
    %cst_2 = constant dense<0.000000e+00> : tensor<128x10xf32>
    %cst_3 = constant dense<0.000000e+00> : tensor<32x10xf32>
    %cst_4 = constant 0.000000e+00 : f32
    %cst_5 = constant 0x7FC00000 : f32
    %cst_6 = constant 0xFF800000 : f32
    %0 = linalg.tensor_collapse_shape %arg0 [[0], [1, 2, 3]] : tensor<32x28x28x1xf32> into tensor<32x784xf32>
    %1 = linalg.init_tensor [32, 128] : tensor<32x128xf32>
    %2 = linalg.fill(%cst_4, %1) : f32, tensor<32x128xf32> -> tensor<32x128xf32>
    %3 = linalg.matmul ins(%0, %cst_0 : tensor<32x784xf32>, tensor<784x128xf32>) outs(%2 : tensor<32x128xf32>) -> tensor<32x128xf32>
    %4 = linalg.init_tensor [32, 128] : tensor<32x128xf32>
    %5 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel"]} ins(%3, %cst_1 : tensor<32x128xf32>, tensor<32x128xf32>) outs(%4 : tensor<32x128xf32>) {
    ^bb0(%arg1: f32, %arg2: f32, %arg3: f32):  // no predecessors
      %33 = addf %arg1, %arg2 : f32
      linalg.yield %33 : f32
    } -> tensor<32x128xf32>
    %6 = linalg.init_tensor [32, 128] : tensor<32x128xf32>
    %7 = linalg.generic {indexing_maps = [#map1, #map0], iterator_types = ["parallel", "parallel"]} ins(%cst : tensor<f32>) outs(%6 : tensor<32x128xf32>) {
    ^bb0(%arg1: f32, %arg2: f32):  // no predecessors
      linalg.yield %arg1 : f32
    } -> tensor<32x128xf32>
    %8 = linalg.init_tensor [32, 128] : tensor<32x128xf32>
    %9 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel"]} ins(%5, %7 : tensor<32x128xf32>, tensor<32x128xf32>) outs(%8 : tensor<32x128xf32>) {
    ^bb0(%arg1: f32, %arg2: f32, %arg3: f32):  // no predecessors
      %33 = cmpf ogt, %arg1, %arg2 : f32
      %34 = select %33, %arg1, %arg2 : f32
      %35 = cmpf uno, %arg1, %arg2 : f32
      %36 = select %35, %cst_5, %34 : f32
      linalg.yield %36 : f32
    } -> tensor<32x128xf32>
    %10 = linalg.init_tensor [32, 10] : tensor<32x10xf32>
    %11 = linalg.fill(%cst_4, %10) : f32, tensor<32x10xf32> -> tensor<32x10xf32>
    %12 = linalg.matmul ins(%9, %cst_2 : tensor<32x128xf32>, tensor<128x10xf32>) outs(%11 : tensor<32x10xf32>) -> tensor<32x10xf32>
    %13 = linalg.init_tensor [32, 10] : tensor<32x10xf32>
    %14 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel"]} ins(%12, %cst_3 : tensor<32x10xf32>, tensor<32x10xf32>) outs(%13 : tensor<32x10xf32>) {
    ^bb0(%arg1: f32, %arg2: f32, %arg3: f32):  // no predecessors
      %33 = addf %arg1, %arg2 : f32
      linalg.yield %33 : f32
    } -> tensor<32x10xf32>
    %15 = linalg.init_tensor [32] : tensor<32xf32>
    %16 = linalg.fill(%cst_6, %15) : f32, tensor<32xf32> -> tensor<32xf32>
    %17 = linalg.generic {indexing_maps = [#map0, #map2], iterator_types = ["parallel", "reduction"]} ins(%14 : tensor<32x10xf32>) outs(%16 : tensor<32xf32>) {
    ^bb0(%arg1: f32, %arg2: f32):  // no predecessors
      %33 = cmpf ogt, %arg1, %arg2 : f32
      %34 = select %33, %arg1, %arg2 : f32
      %35 = cmpf uno, %arg1, %arg2 : f32
      %36 = select %35, %cst_5, %34 : f32
      linalg.yield %36 : f32
    } -> tensor<32xf32>
    %18 = linalg.tensor_expand_shape %17 [[0, 1]] : tensor<32xf32> into tensor<32x1xf32>
    %19 = linalg.init_tensor [32, 10] : tensor<32x10xf32>
    %20 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel"]} ins(%18 : tensor<32x1xf32>) outs(%19 : tensor<32x10xf32>) {
    ^bb0(%arg1: f32, %arg2: f32):  // no predecessors
      linalg.yield %arg1 : f32
    } -> tensor<32x10xf32>
    %21 = linalg.init_tensor [32, 10] : tensor<32x10xf32>
    %22 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel"]} ins(%14, %20 : tensor<32x10xf32>, tensor<32x10xf32>) outs(%21 : tensor<32x10xf32>) {
    ^bb0(%arg1: f32, %arg2: f32, %arg3: f32):  // no predecessors
      %33 = subf %arg1, %arg2 : f32
      linalg.yield %33 : f32
    } -> tensor<32x10xf32>
    %23 = linalg.init_tensor [32, 10] : tensor<32x10xf32>
    %24 = linalg.generic {indexing_maps = [#map0, #map0], iterator_types = ["parallel", "parallel"]} ins(%22 : tensor<32x10xf32>) outs(%23 : tensor<32x10xf32>) {
    ^bb0(%arg1: f32, %arg2: f32):  // no predecessors
      %33 = math.exp %arg1 : f32
      linalg.yield %33 : f32
    } -> tensor<32x10xf32>
    %25 = linalg.init_tensor [32] : tensor<32xf32>
    %26 = linalg.fill(%cst_4, %25) : f32, tensor<32xf32> -> tensor<32xf32>
    %27 = linalg.generic {indexing_maps = [#map0, #map2], iterator_types = ["parallel", "reduction"]} ins(%24 : tensor<32x10xf32>) outs(%26 : tensor<32xf32>) {
    ^bb0(%arg1: f32, %arg2: f32):  // no predecessors
      %33 = addf %arg1, %arg2 : f32
      linalg.yield %33 : f32
    } -> tensor<32xf32>
    %28 = linalg.tensor_expand_shape %27 [[0, 1]] : tensor<32xf32> into tensor<32x1xf32>
    %29 = linalg.init_tensor [32, 10] : tensor<32x10xf32>
    %30 = linalg.generic {indexing_maps = [#map3, #map0], iterator_types = ["parallel", "parallel"]} ins(%28 : tensor<32x1xf32>) outs(%29 : tensor<32x10xf32>) {
    ^bb0(%arg1: f32, %arg2: f32):  // no predecessors
      linalg.yield %arg1 : f32
    } -> tensor<32x10xf32>
    %31 = linalg.init_tensor [32, 10] : tensor<32x10xf32>
    %32 = linalg.generic {indexing_maps = [#map0, #map0, #map0], iterator_types = ["parallel", "parallel"]} ins(%24, %30 : tensor<32x10xf32>, tensor<32x10xf32>) outs(%31 : tensor<32x10xf32>) {
    ^bb0(%arg1: f32, %arg2: f32, %arg3: f32):  // no predecessors
      %33 = divf %arg1, %arg2 : f32
      linalg.yield %33 : f32
    } -> tensor<32x10xf32>
    return %32 : tensor<32x10xf32>
  }
}

// CHECK: 32x10xf32=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
